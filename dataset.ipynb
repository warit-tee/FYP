{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbef6f8f",
   "metadata": {},
   "source": [
    "# Prepare dataset\n",
    "6 columns:\n",
    "- topic\n",
    "- length\n",
    "- AI model\n",
    "- humanizer\n",
    "- AI text\n",
    "- humanized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29390ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many files are in ./datasets/humanized_essays\n",
    "import os\n",
    "def count_files_in_directory(directory):\n",
    "    count = 0\n",
    "    for subdirectory in os.listdir(directory):\n",
    "        subdirectory_path = os.path.join(directory, subdirectory)\n",
    "        if os.path.isdir(subdirectory_path):\n",
    "            count += len(os.listdir(subdirectory_path))\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c8d1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = './datasets/humanized_essays'\n",
    "count_files_in_directory(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1a0798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#create empty dataframe with column topic, length, AI_model\n",
    "df = pd.DataFrame(columns=['topic', 'length', 'AI_model', 'humanizer', 'AI_essay', 'humanized_essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0d1a46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>length</th>\n",
       "      <th>AI_model</th>\n",
       "      <th>humanizer</th>\n",
       "      <th>AI_essay</th>\n",
       "      <th>humanized_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gemini2.5pro</td>\n",
       "      <td>AIHumanizer</td>\n",
       "      <td>The integration of social media into the lives...</td>\n",
       "      <td>The way social media has woven itself into the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gemini2.5pro</td>\n",
       "      <td>Grammarly</td>\n",
       "      <td>The integration of social media into the lives...</td>\n",
       "      <td>Social media has become a big part of young pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gemini2.5pro</td>\n",
       "      <td>HumanizeAI</td>\n",
       "      <td>The integration of social media into the lives...</td>\n",
       "      <td>The penetration of social media into the lives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gemini2.5pro</td>\n",
       "      <td>Quillbot</td>\n",
       "      <td>The integration of social media into the lives...</td>\n",
       "      <td>Social media's introduction into young people'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gemini2.5pro</td>\n",
       "      <td>UndetectableAI</td>\n",
       "      <td>The integration of social media into the lives...</td>\n",
       "      <td>Young people face a harmful environment throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt4.0</td>\n",
       "      <td>Grammarly</td>\n",
       "      <td>Childhood is often remembered through the lens...</td>\n",
       "      <td>Childhood is frequently recalled as a period m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt4.0</td>\n",
       "      <td>HumanizeAI</td>\n",
       "      <td>Childhood is often remembered through the lens...</td>\n",
       "      <td>Childhood is often remembered as a realm of si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt4.0</td>\n",
       "      <td>Quillbot</td>\n",
       "      <td>Childhood is often remembered through the lens...</td>\n",
       "      <td>Childhood is frequently viewed through the pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt4.0</td>\n",
       "      <td>UndetectableAI</td>\n",
       "      <td>Childhood is often remembered through the lens...</td>\n",
       "      <td>People tend to recall their childhood through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt4.0</td>\n",
       "      <td>writehuman.ai</td>\n",
       "      <td>Childhood is often remembered through the lens...</td>\n",
       "      <td>Childhood is remembered as a time of simplicit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic length      AI_model       humanizer  \\\n",
       "0       1      1  gemini2.5pro     AIHumanizer   \n",
       "1       1      1  gemini2.5pro       Grammarly   \n",
       "2       1      1  gemini2.5pro      HumanizeAI   \n",
       "3       1      1  gemini2.5pro        Quillbot   \n",
       "4       1      1  gemini2.5pro  UndetectableAI   \n",
       "..    ...    ...           ...             ...   \n",
       "175     5      3        gpt4.0       Grammarly   \n",
       "176     5      3        gpt4.0      HumanizeAI   \n",
       "177     5      3        gpt4.0        Quillbot   \n",
       "178     5      3        gpt4.0  UndetectableAI   \n",
       "179     5      3        gpt4.0   writehuman.ai   \n",
       "\n",
       "                                              AI_essay  \\\n",
       "0    The integration of social media into the lives...   \n",
       "1    The integration of social media into the lives...   \n",
       "2    The integration of social media into the lives...   \n",
       "3    The integration of social media into the lives...   \n",
       "4    The integration of social media into the lives...   \n",
       "..                                                 ...   \n",
       "175  Childhood is often remembered through the lens...   \n",
       "176  Childhood is often remembered through the lens...   \n",
       "177  Childhood is often remembered through the lens...   \n",
       "178  Childhood is often remembered through the lens...   \n",
       "179  Childhood is often remembered through the lens...   \n",
       "\n",
       "                                       humanized_essay  \n",
       "0    The way social media has woven itself into the...  \n",
       "1    Social media has become a big part of young pe...  \n",
       "2    The penetration of social media into the lives...  \n",
       "3    Social media's introduction into young people'...  \n",
       "4    Young people face a harmful environment throug...  \n",
       "..                                                 ...  \n",
       "175  Childhood is frequently recalled as a period m...  \n",
       "176  Childhood is often remembered as a realm of si...  \n",
       "177  Childhood is frequently viewed through the pri...  \n",
       "178  People tend to recall their childhood through ...  \n",
       "179  Childhood is remembered as a time of simplicit...  \n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read each file in ./datasets/essays and ./datasets/humanized_essays and add to dataframe\n",
    "humanizers = os.listdir('./datasets/humanized_essays')\n",
    "for filename in os.listdir('./datasets/essays'):\n",
    "    file_path = os.path.join('./datasets/essays', filename)\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        topic, length, model = filename.split('_')\n",
    "        topic = topic[5:]\n",
    "        model = model.lower().replace('.txt', '')\n",
    "        for humanizer in humanizers:\n",
    "            humanized_file_path = os.path.join('./datasets/humanized_essays', humanizer, filename)\n",
    "            with open(humanized_file_path, 'r') as humanized_file:\n",
    "                humanized_content = humanized_file.read()\n",
    "                new_df = pd.DataFrame({'topic': [topic],\n",
    "                                       'length': [length],\n",
    "                                       'AI_model': [model],\n",
    "                                       'humanizer': [humanizer],\n",
    "                                       'AI_essay': [content],\n",
    "                                       'humanized_essay': [humanized_content]})\n",
    "            df = pd.concat([df, new_df], ignore_index=True)\n",
    "df = df.sort_values(by=['topic', 'length', 'AI_model', 'humanizer']).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "639bcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df as csv file\n",
    "df.to_csv('datasets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hku",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
